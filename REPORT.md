# Implementation of Linear Predictive Coding (LPC) for Speech Analysis and Synthesis

## *Created by Corinne Darche for MUMT307: Music and Audio Computing II (Winter 2022)*

### Project Description: What is LPC?

Linear Predictive Coding (LPC) is a method for analyzing signals quickly and accurately. As described by O'Shaughnessy (1998), LPC's main draw is that it can accurately estimate vocal fold vibration, the vocal tract's shape, and the different vocal tract resonances. Sawant et al. (2010) went on to explain that LPC's technique predicts a small number of coefficients, which represent different speech parameters, that are then applied in digital filters to create a synthetic version of the original speech signal.
	
This MATLAB script implements a version of the LPC algorithm to analyze and resynthesize an audio file, either with real-time I/O, pre-recorded and saved files, or a combination of the two.

### Project Goals

1. Learn more about speech synthesis. 
   - Most of my experience with language processing has been through the lens of text-based NLP, so this is a natural next step.
   - From the title of this course, this class mostly focuses on pitched sounds. However, if you take a look at the literature surrounding singing voice generation and analysis, the roots come from speech processing. Singing generation and analysis is still a huge challenge and research topic in sound synthesis, so a strong understanding of speech generation concepts is a must.
2. Continue to explore MATLAB's full capabilities
3. Learn more about Linear Predictive Coding
   - It's one of the most popular speech synthesis algorithms for a reason.

### Methodology and Design

The script follows a basic implementation of the LPC algorithm. I started off using an implementation described in MATLAB's DSP Toolbox documentation. However, I wanted to use as little of the toolbox as possible, since it's a black box and it would hinder the learning experience. 
	
The audio I/O options are activated with boolean statements. By default, they're all assigned "false", meaning that the user inputs a file that they want synthesized and it is saved at the end. To prevent the script from crashing, there are mechanisms in place to make sure that the user inputs a valid file name or file path. The complete audio file is divided into frames (defined in the script as 1600) that the algorithm goes through one by one during the analysis.
	
The LPC algorithm can be divided into different sections. First, there's pre-emphasis, where the signal is filtered to give it a smoother spectral shape. This is done using a simple FIR filter with the difference equation `y[n]=x[n]−ax[n−1]` where `0.9<a<1.0`. The audio quality of the final synthesized version decreases as the value of a decreases. Then, the signal passes through a Hanning window to further smooth it for analysis. It then passes through a 12th order autocorrelation sequence. Autocorrelation is the correlation of a signal with a delayed version of itself, and it is a tool used to find repeating patterns. The autocorrelated signal is then sent through the Levinson-Durbin algorithm to determine its reflection coefficients and error.
	
The pre-emphasized signal and the resulting Levinson-Durbin coefficients are then passed through two lattice filters: one is a FIR lattice filter and the other is an IIR filter. This reconstructs the original signal frame by frame for output. Taken from the MATLAB documentation, there is also an option to view the scope of the signal as well as the curve generated by the LPC coefficients.

### Discussion (Challenges, Successes, etc.)

This was a challenging subject to learn as an "outsider". A lot of the resources that I tried to use assumed that I had a strong background in the subject and jumped straight into a lot of mathematical theories. Sources that did show an implementation, like MATLAB's MathWorks documentation, did it in a black-box method. That is, there was no way to see what exactly was happening underneath those functions. Yes, the implementation worked, but I had no idea what they did exactly to get to that finished product. This meant that I had to get creative and do some extra reading and digging to figure out how to implement this on my own.
	
Most of the literature that I found insisted on using a Hamming window to smooth out the signal. Based on what we've learned about windowing techniques, it's a logical choice since it smooths out the envelope and doesn't create a sharp ending on any of the frames. To further confirm my understanding, I tried swapping it out for a rectangular window or a triangular window, only to find that the output would get abruptly cut off before the end of the input file. Hanning and Blackman windows served as good substitutes for the Hamming window, since they have a similar spectra ([see Week 6 notes] (https://www.music.mcgill.ca/~gary/307/week6/node12.html)). 
	
In my initial plan, I wanted to create a GUI for the script and turn it into a proper application. However, MATLAB's GUI is awkward to use. The only option was to create a live script, but the formatting options did not fit the vision that I had in my head. I also wanted to focus less on creating a nice UI and stick to the main objectives of this project. As such, a simple MATLAB script with user I/O and boolean options at the top seemed to be the ideal design choice.
	
Aside from these challenges, I found it rewarding to be able to learn this subject from the ground up. I also got genuinely excited when my implementation worked and the generated sound played. The one issue that I see with my implementation is the file size. LPC promises a synthesized signal at a reduced bit rate. However, when seeing my implementation, I notice that my generated files are significantly larger than my pre-recorded ones. There is a possibility that Apple's algorithm for creating .m4a files on "Voice Memos" is significantly more space efficient than my LPC algorithm.

### Notes for Demo

There are three main boolean options that can be adjusted at the top of the script: `realTimeOutput`, `recordAudioInput`, and `seeScope`.
	
`realTimeOutput` indicates whether or not the script will play the audio output in real-time. If true, the audio plays as the script runs and does not save it as an external file. If false (default), the synthesized output is saved as "LPC_output.m4a".
	
`recordAudioInput` indicates whether or not the script allows the user to record their own voice for input. If true, the script records whatever speech the user says for approximately 5 seconds, saves it as "LPC_input.m4a", and then passes it through the LPC algorithm. If false (default), the user is prompted to enter a valid file name to use as input.
	
`seeScope` toggles the scope view of the synthesized signal and the curve produced by its LPC coefficients. It is automatically set to false.
	
Adjust these boolean values as you see fit and hit run to watch the synthesis. I have included two example recordings taken from my iPhone XR microphone to test out the script.

### References

MathWorks. 2022. "LPC Analysis and Synthesis of Speech." MathWorks. Accessed April 7, 2022. [https://www.mathworks.com/help/dsp/ug/lpc-analysis-and-synthesis-of-speech.html](https://www.mathworks.com/help/dsp/ug/lpc-analysis-and-synthesis-of-speech.html).

O'Shaughnessy, Douglas. 1998. "Linear Predictive Coding." *IEEE Potentials* 7 (1): 29-32.

Sawant, G., A. Singh, K. Kadam, R. Mazarello, and P. Dumane. 2010. "Speech Synthesis Using LPC." In *Proceedings of the International Conference and Workshop of Emerging Trends in Technology*, 515-517.

